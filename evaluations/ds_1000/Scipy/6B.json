[
    {
        "library_id": 0,
        "source_id": 0,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have a set of data and I want to compare which line describes it best (polynomials of different orders, exponential or logarithmic).\nI use Python and Numpy and for polynomial fitting there is a function polyfit(). \nHow do I fit y = Alogx + B using polyfit()? The result should be an np.array of [A, B]\nA:\n<code>\nimport numpy as np\nimport scipy\nx = np.array([1, 7, 20, 50, 79])\ny = np.array([10, 19, 30, 35, 51])\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def best_fit(x, y):\n    \"\"\"\n    Given two lists of numbers, compute best fit line\n    Args:\n        x: list of x values\n        y: list of y values\n    Returns:\n        tuple of (intercept, slope)\n    \"\"\"\n    n = len(x)\n    sum_x = sum(x)\n    sum_y = sum(y)\n    sum_x2 = sum(x**2)\n    sum_xy = sum(x*y)\n    slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x**2)\n    intercept = (sum_y - slope * sum_x) / n\n    return (intercept, slope)"
    },
    {
        "library_id": 1,
        "source_id": 0,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have a set of data and I want to compare which line describes it best (polynomials of different orders, exponential or logarithmic).\nI use Python and Numpy and for polynomial fitting there is a function polyfit(). \nHow do I fit y = A + Blogx using polyfit()? The result should be an np.array of [A, B]\nA:\n<code>\nimport numpy as np\nimport scipy\nx = np.array([1, 7, 20, 50, 79])\ny = np.array([10, 19, 30, 35, 51])\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def polyfit(x, y, degree):\n    results = {}\n    coeffs = np.polyfit(x, y, degree)\n    results['polynomial'] = coeffs.tolist()\n    p = np.poly1d(coeffs)\n    yhat = p(x)\n    ybar = np.sum(y)/len(y)\n    ssreg = np.sum((yhat-ybar)**2)\n    sstot = np.sum((y - ybar)**2)\n    results['determination'] = ssreg / sstot\n    return results"
    },
    {
        "library_id": 2,
        "source_id": 0,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have a set of data and I want to compare which line describes it best (polynomials of different orders, exponential or logarithmic).\nI use Python and Numpy and for polynomial fitting there is a function polyfit(). But I found no such functions for exponential and logarithmic fitting.\nHow do I fit y = A*exp(Bx) + C? The result should be an np.array of [A, B, C]. I know that polyfit performs bad for this function, so I would like to use curve_fit to solve the problem, and it should start from initial guess p0.\nA:\n<code>\nimport numpy as np\nimport scipy.optimize\ny = np.array([1, 7, 20, 50, 79])\nx = np.array([10, 19, 30, 35, 51])\np0 = (4, 0.1, 1)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def func(x, A, B, C):\n    return A*np.exp(B*x) + C"
    },
    {
        "library_id": 3,
        "source_id": 3,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI can't figure out how to do a Two-sample KS test in Scipy.\nAfter reading the documentation scipy kstest\nI can see how to test where a distribution is identical to standard normal distribution\nfrom scipy.stats import kstest\nimport numpy as np\nx = np.random.normal(0,1,1000)\ntest_stat = kstest(x, 'norm')\n#>>> test_stat\n#(0.021080234718821145, 0.76584491300591395)\nWhich means that at p-value of 0.76 we can not reject the null hypothesis that the two distributions are identical.\nHowever, I want to compare two distributions and see if I can reject the null hypothesis that they are identical, something like:\nfrom scipy.stats import kstest\nimport numpy as np\nx = np.random.normal(0,1,1000)\nz = np.random.normal(1.1,0.9, 1000)\nand test whether x and z are identical\nI tried the naive:\ntest_stat = kstest(x, z)\nand got the following error:\nTypeError: 'numpy.ndarray' object is not callable\nIs there a way to do a two-sample KS test in Python? If so, how should I do it?\nThank You in Advance\nA:\n<code>\nfrom scipy import stats\nimport numpy as np\nnp.random.seed(42)\nx = np.random.normal(0, 1, 1000)\ny = np.random.normal(0, 1, 1000)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(statistic, p_value)\n</code>\n\n\ndef",
        "answer": "def kstest(x, y):\n    \"\"\"\n    Tests whether two samples are drawn from the same distribution.\n    Parameters\n    ----------\n    x : array_like\n        The first sample of observations.\n    y : array_like\n        The second sample of observations.\n    Returns\n    -------\n    statistic : float\n        The KS statistic.\n    p_value : float\n        The two-tailed p-value.\n    \"\"\"\n    statistic, p_value = stats.kstest(x, y)\n    return statistic, p_value"
    },
    {
        "library_id": 4,
        "source_id": 3,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI can't figure out how to do a Two-sample KS test in Scipy.\nAfter reading the documentation scipy kstest\nI can see how to test where a distribution is identical to standard normal distribution\nfrom scipy.stats import kstest\nimport numpy as np\nx = np.random.normal(0,1,1000)\ntest_stat = kstest(x, 'norm')\n#>>> test_stat\n#(0.021080234718821145, 0.76584491300591395)\nWhich means that at p-value of 0.76 we can not reject the null hypothesis that the two distributions are identical.\nHowever, I want to compare two distributions and see if I can reject the null hypothesis that they are identical, something like:\nfrom scipy.stats import kstest\nimport numpy as np\nx = np.random.normal(0,1,1000)\nz = np.random.normal(1.1,0.9, 1000)\nand test whether x and z are identical\nI tried the naive:\ntest_stat = kstest(x, z)\nand got the following error:\nTypeError: 'numpy.ndarray' object is not callable\nIs there a way to do a two-sample KS test in Python, then test whether I can reject the null hypothesis that the two distributions are identical(result=True means able to reject, and the vice versa) based on alpha? If so, how should I do it?\nThank You in Advance\nA:\n<code>\nfrom scipy import stats\nimport numpy as np\nnp.random.seed(42)\nx = np.random.normal(0, 1, 1000)\ny = np.random.normal(0, 1, 1000)\nalpha = 0.01\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def two_sample_ks_test(x, y, alpha=0.01):\n    \"\"\"\n    Performs a two-sample Kolmogorov-Smirnov test for goodness-of-fit."
    },
    {
        "library_id": 5,
        "source_id": 5,
        "prompt": "Complete the Python function given the prompt below:Problem:\nAccording to the SciPy documentation it is possible to minimize functions with multiple variables, yet it doesn't tell how to optimize on such functions.\nfrom scipy.optimize import minimize\nfrom math import *\ndef f(c):\n  return sqrt((sin(pi/2) + sin(0) + sin(c) - 2)**2 + (cos(pi/2) + cos(0) + cos(c) - 1)**2)\nprint minimize(f, 3.14/2 + 3.14/7)\nThe above code does try to minimize the function f, but for my task I need to minimize with respect to three variables, starting from `initial_guess`.\nSimply introducing a second argument and adjusting minimize accordingly yields an error (TypeError: f() takes exactly 2 arguments (1 given)).\nHow does minimize work when minimizing with multiple variables.\nI need to minimize f(a,b,c)=((a+b-c)-2)**2 + ((3*a-b-c))**2 + sin(b) + cos(b) + 4.\nResult should be a list=[a,b,c], the parameters of minimized function.\nA:\n<code>\nimport scipy.optimize as optimize\nfrom math import *\ninitial_guess = [-1, 0, -3]\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def f(a,b,c):\n  return ((a+b-c)-2)**2 + ((3*a-b-c))**2 + sin(b) + cos(b) + 4"
    },
    {
        "library_id": 6,
        "source_id": 6,
        "prompt": "Complete the Python function given the prompt below:Problem:\nHow does one convert a list of Z-scores from the Z-distribution (standard normal distribution, Gaussian distribution) to left-tailed p-values? I have yet to find the magical function in Scipy's stats module to do this, but one must be there.\nA:\n<code>\nimport numpy as np\nimport scipy.stats\nz_scores = np.array([-3, -2, 0, 2, 2.5])\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(p_values)\n</code>\n\n\ndef",
        "answer": "def p_values(z_scores):\n    \"\"\"\n    Convert the Z-scores to p-values.\n    \"\"\"\n    p_values = scipy.stats.norm.sf(z_scores)\n    return p_values"
    },
    {
        "library_id": 7,
        "source_id": 6,
        "prompt": "Complete the Python function given the prompt below:Problem:\nHow does one convert a list of Z-scores from the Z-distribution (standard normal distribution, Gaussian distribution) to left-tailed p-values? Original data is sampled from X ~ N(mu, sigma). I have yet to find the magical function in Scipy's stats module to do this, but one must be there.\nA:\n<code>\nimport scipy.stats\nimport numpy as np\nz_scores = [-3, -2, 0, 2, 2.5]\nmu = 3\nsigma = 4\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(p_values)\n</code>\n\n\ndef",
        "answer": "def p_values(z_scores):\n    \"\"\"\n    Given a list of Z-scores, return a list of p-values.\n    \"\"\"\n    # TODO: Implement this function.\n    # Hint: Use the Z-score to get the p-value.\n    # Hint: Use the scipy.stats.norm.cdf() function to compute the p-value.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use the scipy.stats.norm.cdf() function.\n    # Hint: You'll need to use"
    },
    {
        "library_id": 8,
        "source_id": 6,
        "prompt": "Complete the Python function given the prompt below:Problem:\nHow does one convert a left-tailed p-value to a z_score from the Z-distribution (standard normal distribution, Gaussian distribution)? I have yet to find the magical function in Scipy's stats module to do this, but one must be there.\nA:\n<code>\nimport numpy as np\nimport scipy.stats\np_values = [0.1, 0.225, 0.5, 0.75, 0.925, 0.95]\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(z_scores)\n</code>\n\n\ndef",
        "answer": "def z_score(p_value):\n    return scipy.stats.norm.ppf(p_value)"
    },
    {
        "library_id": 9,
        "source_id": 9,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have been trying to get the result of a lognormal distribution using Scipy. I already have the Mu and Sigma, so I don't need to do any other prep work. If I need to be more specific (and I am trying to be with my limited knowledge of stats), I would say that I am looking for the cumulative function (cdf under Scipy). The problem is that I can't figure out how to do this with just the mean and standard deviation on a scale of 0-1 (ie the answer returned should be something from 0-1). I'm also not sure which method from dist, I should be using to get the answer. I've tried reading the documentation and looking through SO, but the relevant questions (like this and this) didn't seem to provide the answers I was looking for.\nHere is a code sample of what I am working with. Thanks. Here mu and stddev stands for mu and sigma in probability density function of lognorm.\nfrom scipy.stats import lognorm\nstddev = 0.859455801705594\nmu = 0.418749176686875\ntotal = 37\ndist = lognorm.cdf(total,mu,stddev)\nUPDATE:\nSo after a bit of work and a little research, I got a little further. But I still am getting the wrong answer. The new code is below. According to R and Excel, the result should be.7434, but that's clearly not what is happening. Is there a logic flaw I am missing?\nstddev = 2.0785\nmu = 1.744\nx = 25\ndist = lognorm([mu],loc=stddev)\ndist.cdf(x)  # yields=0.96374596, expected=0.7434\nA:\n<code>\nimport numpy as np\nfrom scipy import stats\nstddev = 2.0785\nmu = 1.744\nx = 25\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def lognorm_cdf(x,mu,stddev):\n    dist = stats.lognorm(s=stddev,scale=np.exp(mu))\n    return dist.cdf(x)"
    },
    {
        "library_id": 10,
        "source_id": 9,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have been trying to get the arithmetic result of a lognormal distribution using Scipy. I already have the Mu and Sigma, so I don't need to do any other prep work. If I need to be more specific (and I am trying to be with my limited knowledge of stats), I would say that I am looking for the expected value and median of the distribution. The problem is that I can't figure out how to do this with just the mean and standard deviation. I'm also not sure which method from dist, I should be using to get the answer. I've tried reading the documentation and looking through SO, but the relevant questions (like this and this) didn't seem to provide the answers I was looking for.\nHere is a code sample of what I am working with. Thanks. Here mu and stddev stands for mu and sigma in probability density function of lognorm.\nfrom scipy.stats import lognorm\nstddev = 0.859455801705594\nmu = 0.418749176686875\ntotal = 37\ndist = lognorm(total,mu,stddev)\nWhat should I do next?\nA:\n<code>\nimport numpy as np\nfrom scipy import stats\nstddev = 2.0785\nmu = 1.744\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(expected_value, median)\n</code>\n\n\ndef",
        "answer": "def lognorm_expected_value(mu, stddev):\n    return np.exp(mu + stddev**2/2)"
    },
    {
        "library_id": 11,
        "source_id": 11,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have this example of matrix by matrix multiplication using numpy arrays:\nimport numpy as np\nm = np.array([[1,2,3],[4,5,6],[7,8,9]])\nc = np.array([0,1,2])\nm * c\narray([[ 0,  2,  6],\n       [ 0,  5, 12],\n       [ 0,  8, 18]])\nHow can i do the same thing if m is scipy sparse CSR matrix? The result should be csr_matrix as well.\nThis gives dimension mismatch:\nsp.sparse.csr_matrix(m)*sp.sparse.csr_matrix(c)\nA:\n<code>\nfrom scipy import sparse\nimport numpy as np\nsa = sparse.csr_matrix(np.array([[1,2,3],[4,5,6],[7,8,9]]))\nsb = sparse.csr_matrix(np.array([0,1,2]))\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def matrix_multiplication(m, c):\n    # Complete this function\n    # You need to return result, which should be a csr_matrix\n    # result =...\n    # return result\n    import scipy.sparse as sp\n    import numpy as np\n    sa = sp.csr_matrix(np.array([[1,2,3],[4,5,6],[7,8,9]]))\n    sb = sp.csr_matrix(np.array([0,1,2]))\n    result = sp.csr_matrix(m)*sp.csr_matrix(c)\n    return result"
    },
    {
        "library_id": 12,
        "source_id": 11,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have this example of matrix by matrix multiplication using numpy arrays:\nimport numpy as np\nm = np.array([[1,2,3],[4,5,6],[7,8,9]])\nc = np.array([0,1,2])\nm * c\narray([[ 0,  2,  6],\n       [ 0,  5, 12],\n       [ 0,  8, 18]])\nHow can i do the same thing if m is scipy sparse CSR matrix? The result should be csr_matrix as well.\nThis gives dimension mismatch:\nsp.sparse.csr_matrix(m)*sp.sparse.csr_matrix(c)\nA:\n<code>\nfrom scipy import sparse\nimport numpy as np\nexample_sA = sparse.csr_matrix(np.array([[1,2,3],[4,5,6],[7,8,9]]))\nexample_sB = sparse.csr_matrix(np.array([0,1,2]))\ndef f(sA = example_sA, sB = example_sB):\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\n    return result\n</code>\n\n\ndef",
        "answer": "def f(sA = example_sA, sB = example_sB):\n    return result\n</code>"
    },
    {
        "library_id": 13,
        "source_id": 13,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have some data that comes in the form (x, y, z, V) where x,y,z are distances, and V is the moisture. I read a lot on StackOverflow about interpolation by python like this and this valuable posts, but all of them were about regular grids of x, y, z. i.e. every value of x contributes equally with every point of y, and every point of z. On the other hand, my points came from 3D finite element grid (as below), where the grid is not regular. \nThe two mentioned posts 1 and 2, defined each of x, y, z as a separate numpy array then they used something like cartcoord = zip(x, y) then scipy.interpolate.LinearNDInterpolator(cartcoord, z) (in a 3D example). I can not do the same as my 3D grid is not regular, thus not each point has a contribution to other points, so if when I repeated these approaches I found many null values, and I got many errors.\nHere are 10 sample points in the form of [x, y, z, V]\ndata = [[27.827, 18.530, -30.417, 0.205], [24.002, 17.759, -24.782, 0.197], \n[22.145, 13.687, -33.282, 0.204], [17.627, 18.224, -25.197, 0.197], \n[29.018, 18.841, -38.761, 0.212], [24.834, 20.538, -33.012, 0.208], \n[26.232, 22.327, -27.735, 0.204], [23.017, 23.037, -29.230, 0.205], \n[28.761, 21.565, -31.586, 0.211], [26.263, 23.686, -32.766, 0.215]]\nI want to get the interpolated value V of the point (25, 20, -30).\nHow can I get it?\nA:\n<code>\nimport numpy as np\nimport scipy.interpolate\npoints = np.array([\n        [ 27.827,  18.53, -30.417], [ 24.002,  17.759, -24.782],\n        [ 22.145,  13.687, -33.282], [ 17.627,  18.224, -25.197],\n        [ 29.018,  18.841, -38.761], [ 24.834,  20.538, -33.012],\n        [ 26.232,  22.327, -27.735], [ 23.017,  23.037, -29.23 ],\n        [ 28.761,  21.565, -31.586], [ 26.263,  23.686, -32.766]])\nV = np.array([0.205,  0.197,  0.204,  0.197,  0.212,\n                   0.208,  0.204,  0.205, 0.211,  0.215])\nrequest = np.array([[25, 20, -30]])\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def interpolate(data, request):\n    \"\"\"\n    This function interpolates the moisture values at the requested point.\n    \"\"\"\n    # YOUR CODE HERE\n    # END SOLUTION\n    return result"
    },
    {
        "library_id": 14,
        "source_id": 13,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have some data that comes in the form (x, y, z, V) where x,y,z are distances, and V is the moisture. I read a lot on StackOverflow about interpolation by python like this and this valuable posts, but all of them were about regular grids of x, y, z. i.e. every value of x contributes equally with every point of y, and every point of z. On the other hand, my points came from 3D finite element grid (as below), where the grid is not regular. \nThe two mentioned posts 1 and 2, defined each of x, y, z as a separate numpy array then they used something like cartcoord = zip(x, y) then scipy.interpolate.LinearNDInterpolator(cartcoord, z) (in a 3D example). I can not do the same as my 3D grid is not regular, thus not each point has a contribution to other points, so if when I repeated these approaches I found many null values, and I got many errors.\nHere are 10 sample points in the form of [x, y, z, V]\ndata = [[27.827, 18.530, -30.417, 0.205], [24.002, 17.759, -24.782, 0.197], \n[22.145, 13.687, -33.282, 0.204], [17.627, 18.224, -25.197, 0.197], \n[29.018, 18.841, -38.761, 0.212], [24.834, 20.538, -33.012, 0.208], \n[26.232, 22.327, -27.735, 0.204], [23.017, 23.037, -29.230, 0.205], \n[28.761, 21.565, -31.586, 0.211], [26.263, 23.686, -32.766, 0.215]]\nI want to get the interpolated value V of the point (25, 20, -30) and (27, 20, -32) as a list.\nHow can I get it?\nA:\n<code>\nimport numpy as np\nimport scipy.interpolate\npoints = np.array([\n        [ 27.827,  18.53, -30.417], [ 24.002,  17.759, -24.782],\n        [ 22.145,  13.687, -33.282], [ 17.627,  18.224, -25.197],\n        [ 29.018,  18.841, -38.761], [ 24.834,  20.538, -33.012],\n        [ 26.232,  22.327, -27.735], [ 23.017,  23.037, -29.23 ],\n        [ 28.761,  21.565, -31.586], [ 26.263,  23.686, -32.766]])\nV = np.array([0.205,  0.197,  0.204,  0.197,  0.212,\n                   0.208,  0.204,  0.205, 0.211,  0.215])\nrequest = np.array([[25, 20, -30], [27, 20, -32]])\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def interpolate(data, request):\n    # your code here\n    return result"
    },
    {
        "library_id": 15,
        "source_id": 15,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have a numpy array for an image that I read in from a FITS file. I rotated it by N degrees using scipy.ndimage.interpolation.rotate. Then I want to figure out where some point (x,y) in the original non-rotated frame ends up in the rotated image -- i.e., what are the rotated frame coordinates (x',y')?\nThis should be a very simple rotation matrix problem but if I do the usual mathematical or programming based rotation equations, the new (x',y') do not end up where they originally were. I suspect this has something to do with needing a translation matrix as well because the scipy rotate function is based on the origin (0,0) rather than the actual center of the image array.\nCan someone please tell me how to get the rotated frame (x',y')? As an example, you could use\nfrom scipy import misc\nfrom scipy.ndimage import rotate\ndata_orig = misc.face()\ndata_rot = rotate(data_orig,66) # data array\nx0,y0 = 580,300 # left eye; (xrot,yrot) should point there\nA:\n<code>\nfrom scipy import misc\nfrom scipy.ndimage import rotate\nimport numpy as np\ndata_orig = misc.face()\nx0,y0 = 580,300 # left eye; (xrot,yrot) should point there\nangle = np.random.randint(1, 360)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(data_rot, (xrot, yrot))\n</code>\n\n\ndef",
        "answer": "def rotate(data, angle):\n    \"\"\"\n    Rotate an image by angle degrees.\n    \"\"\"\n    return scipy.ndimage.interpolation.rotate(data, angle)"
    },
    {
        "library_id": 16,
        "source_id": 16,
        "prompt": "Complete the Python function given the prompt below:Problem:\nHow can I extract the main diagonal(1-d array) of a sparse matrix? The matrix is created in scipy.sparse. I want equivalent of np.diagonal(), but for sparse matrix.\nA:\n<code>\nimport numpy as np\nfrom scipy.sparse import csr_matrix\narr = np.random.rand(4, 4)\nM = csr_matrix(arr)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def main():\n    pass"
    },
    {
        "library_id": 17,
        "source_id": 17,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI simulate times in the range 0 to T according to a Poisson process. The inter-event times are exponential and we know that the distribution of the times should be uniform in the range 0 to T.\ndef poisson_simul(rate, T):\n    time = random.expovariate(rate)\n    times = [0]\n    while (times[-1] < T):\n        times.append(time+times[-1])\n        time = random.expovariate(rate)\n    return times[1:]\nI would simply like to run one of the tests for uniformity, for example the Kolmogorov-Smirnov test. I can't work out how to do this in scipy however. If I do\nimport random\nfrom scipy.stats import kstest\ntimes = poisson_simul(1, 100)\nprint kstest(times, \"uniform\") \nit is not right. It gives me\n(1.0, 0.0)\nI just want to test the hypothesis that the points are uniformly chosen from the range 0 to T. How do you do this in scipy? The result should be KStest result.\nA:\n<code>\nfrom scipy import stats\nimport random\nimport numpy as np\ndef poisson_simul(rate, T):\n    time = random.expovariate(rate)\n    times = [0]\n    while (times[-1] < T):\n        times.append(time+times[-1])\n        time = random.expovariate(rate)\n    return times[1:]\nrate = 1.0\nT = 100.0\ntimes = poisson_simul(rate, T)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def poisson_simul(rate, T):\n    time = random.expovariate(rate)\n    times = [0]\n    while (times[-1] < T):\n        times.append(time+times[-1])\n        time = random.expovariate(rate)\n    return times[1:]\nrate = 1.0\nT = 100.0\ntimes = poisson_simul(rate, T)\nresult = stats.kstest(times, 'uniform')\nprint(result)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>"
    },
    {
        "library_id": 18,
        "source_id": 17,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI simulate times in the range 0 to T according to a Poisson process. The inter-event times are exponential and we know that the distribution of the times should be uniform in the range 0 to T.\ndef poisson_simul(rate, T):\n    time = random.expovariate(rate)\n    times = [0]\n    while (times[-1] < T):\n        times.append(time+times[-1])\n        time = random.expovariate(rate)\n    return times[1:]\nI would simply like to run one of the tests for uniformity, for example the Kolmogorov-Smirnov test. I can't work out how to do this in scipy however. If I do\nimport random\nfrom scipy.stats import kstest\ntimes = poisson_simul(1, 100)\nprint kstest(times, \"uniform\") \nit is not right. It gives me\n(1.0, 0.0)\nI just want to test the hypothesis that the points are uniformly chosen from the range 0 to T. How do you do this in scipy? The result should be KStest result.\nA:\n<code>\nfrom scipy import stats\nimport random\nimport numpy as np\ndef poisson_simul(rate, T):\n    time = random.expovariate(rate)\n    times = [0]\n    while (times[-1] < T):\n        times.append(time+times[-1])\n        time = random.expovariate(rate)\n    return times[1:]\nexample_rate = 1.0\nexample_T = 100.0\nexample_times = poisson_simul(example_rate, example_T)\ndef f(times = example_times, rate = example_rate, T = example_T):\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\n    return result\n</code>\n\n\ndef",
        "answer": "def f(times = example_times, rate = example_rate, T = example_T):\n    return stats.kstest(times, \"uniform\")"
    },
    {
        "library_id": 19,
        "source_id": 17,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI simulate times in the range 0 to T according to a Poisson process. The inter-event times are exponential and we know that the distribution of the times should be uniform in the range 0 to T.\ndef poisson_simul(rate, T):\n    time = random.expovariate(rate)\n    times = [0]\n    while (times[-1] < T):\n        times.append(time+times[-1])\n        time = random.expovariate(rate)\n    return times[1:]\nI would simply like to run one of the tests for uniformity, for example the Kolmogorov-Smirnov test. I can't work out how to do this in scipy however. If I do\nimport random\nfrom scipy.stats import kstest\ntimes = poisson_simul(1, 100)\nprint kstest(times, \"uniform\") \nit is not right. It gives me\n(1.0, 0.0)\nI just want to test the hypothesis that the points are uniformly chosen from the range 0 to T. How do you do this in scipy? Another question is how to interpret the result? What I want is just `True` for unifomity or `False` vice versa. Suppose I want a confidence level of 95%.\nA:\n<code>\nfrom scipy import stats\nimport random\nimport numpy as np\ndef poisson_simul(rate, T):\n    time = random.expovariate(rate)\n    times = [0]\n    while (times[-1] < T):\n        times.append(time+times[-1])\n        time = random.expovariate(rate)\n    return times[1:]\nrate = 1.0\nT = 100.0\ntimes = poisson_simul(rate, T)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def uniform_test(times, alpha):\n    return stats.kstest(times, 'uniform')"
    },
    {
        "library_id": 20,
        "source_id": 20,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have two csr_matrix, c1, c2.\nI want a new matrix Feature = [c1, c2]. But if I directly concatenate them horizontally this way, there's an error that says the matrix Feature is a list. How can I achieve the matrix concatenation and still get the same type of matrix, i.e. a csr_matrix?\nAnd it doesn't work if I do this after the concatenation: Feature = csr_matrix(Feature) It gives the error:\nTraceback (most recent call last):\n  File \"yelpfilter.py\", line 91, in <module>\n    Feature = csr_matrix(Feature)\n  File \"c:\\python27\\lib\\site-packages\\scipy\\sparse\\compressed.py\", line 66, in __init__\n    self._set_self( self.__class__(coo_matrix(arg1, dtype=dtype)) )\n  File \"c:\\python27\\lib\\site-packages\\scipy\\sparse\\coo.py\", line 185, in __init__\n    self.row, self.col = M.nonzero()\nTypeError: __nonzero__ should return bool or int, returned numpy.bool_\nA:\n<code>\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\n#print(Feature)\n</code>\n\n\ndef",
        "answer": "def yelpfilter(A, B):\n    #return Feature\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_mat"
    },
    {
        "library_id": 21,
        "source_id": 20,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have two csr_matrix, c1 and c2.\nI want a new sparse matrix Feature = [c1, c2], that is, to stack c1 and c2 horizontally to get a new sparse matrix.\nTo make use of sparse matrix's memory efficiency, I don't want results as dense arrays.\nBut if I directly concatenate them this way, there's an error that says the matrix Feature is a list.\nAnd if I try this: Feature = csr_matrix(Feature) It gives the error:\nTraceback (most recent call last):\n  File \"yelpfilter.py\", line 91, in <module>\n    Feature = csr_matrix(Feature)\n  File \"c:\\python27\\lib\\site-packages\\scipy\\sparse\\compressed.py\", line 66, in __init__\n    self._set_self( self.__class__(coo_matrix(arg1, dtype=dtype)) )\n  File \"c:\\python27\\lib\\site-packages\\scipy\\sparse\\coo.py\", line 185, in __init__\n    self.row, self.col = M.nonzero()\nTypeError: __nonzero__ should return bool or int, returned numpy.bool_\nAny help would be appreciated!\nA:\n<code>\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\n#print(Feature)\n</code>\n\n\ndef",
        "answer": "def yelpfilter(c1, c2):\n    #return Feature\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr_matrix(Feature)\n    #return Feature = csr"
    },
    {
        "library_id": 22,
        "source_id": 20,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have two csr_matrix, c1 and c2.\nI want a new matrix \nFeature = [c1\n           c2]. \n          \nThat is, I want to concatenate c1 and c2 in vertical direction.          \nBut I don't know how to represent the concatenation or how to form the format.\nHow can I achieve the matrix concatenation and still get the same type of matrix, i.e. a csr_matrix?\nAny help would be appreciated.\nA:\n<code>\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\n#print(Feature)\n</code>\n\n\ndef",
        "answer": "def concatenate(c1, c2):\n    #print(c1)\n    #print(c2)\n    #print(c1.shape)\n    #print(c2.shape)\n    #print(c1.shape[0])\n    #print(c2.shape[0])\n    #print(c1.shape[1])\n    #print(c2.shape[1])\n    #print(c1.shape[0] + c2.shape[0])\n    #print(c1.shape[1] + c2.shape[1])\n    #print(c1.shape)\n    #print(c2.shape)\n    #print(c1.shape[0] + c2.shape[0])\n    #print(c1.shape[1] + c2.shape[1])\n    #print(c1.shape)\n    #print(c2.shape)\n    #print(c1.shape[0] + c2.shape[0])\n    #print(c1.shape[1] + c2.shape[1])\n    #print(c1.shape)\n    #print(c2.shape)\n    #print(c1.shape[0] + c2.shape[0])\n    #print(c1.shape[1] + c2.shape[1])\n    #print(c1.shape)\n    #print(c2.shape)\n    #print(c1.shape[0] + c2.shape[0])\n    #print(c1.shape[1] + c2.shape[1])\n    #print(c1.shape)\n    #print(c2.shape)\n    #print(c1.shape[0] + c2.shape[0])\n    #print(c1.shape[1] + c2.shape[1])\n    #print(c1.shape)\n    #print(c2.shape)\n    #print(c1.shape[0] + c2.shape[0])\n    #print(c1.shape[1] + c2.shape[1])\n    #print(c"
    },
    {
        "library_id": 23,
        "source_id": 23,
        "prompt": "Complete the Python function given the prompt below:Problem:\nGiven two sets of points in n-dimensional space, how can one map points from one set to the other, such that each point is only used once and the total euclidean distance between the pairs of points is minimized?\nFor example,\nimport matplotlib.pyplot as plt\nimport numpy as np\n# create six points in 2d space; the first three belong to set \"A\" and the\n# second three belong to set \"B\"\nx = [1, 2, 3, 1.8, 1.9, 3.4]\ny = [2, 3, 1, 2.6, 3.4, 0.4]\ncolors = ['red'] * 3 + ['blue'] * 3\nplt.scatter(x, y, c=colors)\nplt.show()\nSo in the example above, the goal would be to map each red point to a blue point such that each blue point is only used once and the sum of the distances between points is minimized.\nThe application I have in mind involves a fairly small number of datapoints in 3-dimensional space, so the brute force approach might be fine, but I thought I would check to see if anyone knows of a more efficient or elegant solution first. \nThe result should be an assignment of points in second set to corresponding elements in the first set.\nFor example, a matching solution is\nPoints1 <-> Points2\n    0   ---     2\n    1   ---     0\n    2   ---     1\nand the result is [2, 0, 1]\nA:\n<code>\nimport numpy as np\nimport scipy.spatial\nimport scipy.optimize\npoints1 = np.array([(x, y) for x in np.linspace(-1,1,7) for y in np.linspace(-1,1,7)])\nN = points1.shape[0]\npoints2 = 2*np.random.rand(N,2)-1\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def assignment(points1, points2):\n    \"\"\"\n    Given two sets of points in n-dimensional space, how can one map points from one set to the other, such that each point is only used once and the total euclidean distance between the pairs of points is minimized?\n    For example,\n    import matplotlib.pyplot as plt\n    import numpy as np\n    # create six points in 2d space; the first three belong to set \"A\" and the\n    # second three belong to set \"B\"\n    x = [1, 2, 3, 1.8, 1.9, 3.4]\n    y = [2, 3, 1, 2.6, 3.4, 0.4]\n    colors = ['red'] * 3 + ['blue'] * 3\n    plt.scatter(x, y, c=colors)\n    plt.show()\n    So in the example above, the goal would be to map each red point to a blue point such that each blue point is only used once and the sum of the distances between points is minimized.\n    The application I have in mind involves a fairly small number of datapoints in 3-dimensional space, so the brute force approach might be fine, but I thought I would check to see if anyone knows of a more elegant solution first. \n    The result should be an assignment of points in second set to corresponding elements in the first set.\n    For example, a matching solution is\n    Points1 <-> Points2\n    0   ---     2\n    1   ---     0\n    2   ---     1\n    and the result is [2, 0, 1]\n    A:\n    <code>\n    import numpy as np\n    import scipy.spatial\n    import scipy.optimize\n    points1 = np.array([(x, y) for x in np.linspace(-1,1,7) for y in np.linspace(-1,1,7)])\n    N = points1.shape[0]\n    points2 = 2*np.random.rand(N,2)-1\n    </code>\n    BEGIN SOLUTION\n    <code>\n    [insert]\n    </code>"
    },
    {
        "library_id": 24,
        "source_id": 23,
        "prompt": "Complete the Python function given the prompt below:Problem:\nGiven two sets of points in n-dimensional space, how can one map points from one set to the other, such that each point is only used once and the total Manhattan distance between the pairs of points is minimized?\nFor example,\nimport matplotlib.pyplot as plt\nimport numpy as np\n# create six points in 2d space; the first three belong to set \"A\" and the\n# second three belong to set \"B\"\nx = [1, 2, 3, 1.8, 1.9, 3.4]\ny = [2, 3, 1, 2.6, 3.4, 0.4]\ncolors = ['red'] * 3 + ['blue'] * 3\nplt.scatter(x, y, c=colors)\nplt.show()\nSo in the example above, the goal would be to map each red point to a blue point such that each blue point is only used once and the sum of the distances between points is minimized.\nThe application I have in mind involves a fairly small number of datapoints in 3-dimensional space, so the brute force approach might be fine, but I thought I would check to see if anyone knows of a more efficient or elegant solution first.\nThe result should be an assignment of points in second set to corresponding elements in the first set.\nFor example, a matching solution is\nPoints1 <-> Points2\n    0   ---     2\n    1   ---     0\n    2   ---     1\nand the result is [2, 0, 1]\nA:\n<code>\nimport numpy as np\nimport scipy.spatial\nimport scipy.optimize\npoints1 = np.array([(x, y) for x in np.linspace(-1,1,7) for y in np.linspace(-1,1,7)])\nN = points1.shape[0]\npoints2 = 2*np.random.rand(N,2)-1\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def assignment(points1, points2):\n    \"\"\"\n    Given two sets of points in n-dimensional space, how can one map points from one set to the other, such that each point is only used once and the total Manhattan distance between the pairs of points is minimized?\n    For example,\n    import matplotlib.pyplot as plt\n    import numpy as np\n    # create six points in 2d space; the first three belong to set \"A\" and the\n    # second three belong to set \"B\"\n    x = [1, 2, 3, 1.8, 1.9, 3.4]\n    y = [2, 3, 1, 2.6, 3.4, 0.4]\n    colors = ['red'] * 3 + ['blue'] * 3\n    plt.scatter(x, y, c=colors)\n    plt.show()\n    So in the example above, the goal would be to map each red point to a blue point such that each blue point is only used once and the sum of the distances between points is minimized.\n    The application I have in mind involves a fairly small number of datapoints in 3-dimensional space, so the brute force approach might be fine, but I thought I would check to see if anyone knows of a more elegant or elegant solution first.\n    The result should be an assignment of points in second set to corresponding elements in the first set.\n    For example, a matching solution is\n    Points1 <-> Points2\n    0   ---     2\n    1   ---     0\n    2   ---     1\n    and the result is [2, 0, 1]\n    A:\n    <code>\n    import numpy as np\n    import scipy.spatial\n    import scipy.optimize\n    points1 = np.array([(x, y) for x in np.linspace(-1,1,7) for y in np.linspace(-1,1,7)])\n    N = points1.shape[0]\n    points2 = 2*np.random.rand(N,2)-1\n    </code>\n    BEGIN SOLUTION\n    <code>\n    [insert]\n    </code>\n    "
    },
    {
        "library_id": 25,
        "source_id": 25,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI want to remove diagonal elements from a sparse matrix. Since the matrix is sparse, these elements shouldn't be stored once removed.\nScipy provides a method to set diagonal elements values: setdiag\nIf I try it using lil_matrix, it works:\n>>> a = np.ones((2,2))\n>>> c = lil_matrix(a)\n>>> c.setdiag(0)\n>>> c\n<2x2 sparse matrix of type '<type 'numpy.float64'>'\n    with 2 stored elements in LInked List format>\nHowever with csr_matrix, it seems diagonal elements are not removed from storage:\n>>> b = csr_matrix(a)\n>>> b\n<2x2 sparse matrix of type '<type 'numpy.float64'>'\n    with 4 stored elements in Compressed Sparse Row format>\n>>> b.setdiag(0)\n>>> b\n<2x2 sparse matrix of type '<type 'numpy.float64'>'\n    with 4 stored elements in Compressed Sparse Row format>\n>>> b.toarray()\narray([[ 0.,  1.],\n       [ 1.,  0.]])\nThrough a dense array, we have of course:\n>>> csr_matrix(b.toarray())\n<2x2 sparse matrix of type '<type 'numpy.float64'>'\n    with 2 stored elements in Compressed Sparse Row format>\nIs that intended? If so, is it due to the compressed format of csr matrices? Is there any workaround else than going from sparse to dense to sparse again?\nA:\n<code>\nfrom scipy import sparse\nimport numpy as np\na = np.ones((2, 2))\nb = sparse.csr_matrix(a)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(b)\n</code>\n\n\ndef",
        "answer": "def setdiag(self, values, k=0):\n    if not self.has_sorted_indices:\n        self.sort_indices()\n    M, N = self.shape\n    if k < 0:\n        k += M\n    if k > 0:\n        max_index = min(M, N - k)\n    else:\n        max_index = M\n    self.indices[:max_index] = values"
    },
    {
        "library_id": 26,
        "source_id": 26,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI am working with a 2D numpy array made of 512x512=262144 values. Such values are of float type and range from 0.0 to 1.0. The array has an X,Y coordinate system which originates in the top left corner: thus, position (0,0) is in the top left corner, while position (512,512) is in the bottom right corner.\nThis is how the 2D array looks like (just an excerpt):\nX,Y,Value\n0,0,0.482\n0,1,0.49\n0,2,0.496\n0,3,0.495\n0,4,0.49\n0,5,0.489\n0,6,0.5\n0,7,0.504\n0,8,0.494\n0,9,0.485\nI would like to be able to:\nCount the number of regions of cells which value exceeds a given threshold, i.e. 0.75;\nNote: If two elements touch horizontally, vertically or diagnoally, they belong to one region.\nA:\n<code>\nimport numpy as np\nfrom scipy import ndimage\nnp.random.seed(10)\ngen = np.random.RandomState(0)\nimg = gen.poisson(2, size=(512, 512))\nimg = ndimage.gaussian_filter(img.astype(np.double), (30, 30))\nimg -= img.min()\nimg /= img.max()\nthreshold = 0.75\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def solution(img, threshold):\n    # Write your code here\n    # BEGIN SOLUTION\n    [insert]\n    # END SOLUTION"
    },
    {
        "library_id": 27,
        "source_id": 26,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI am working with a 2D numpy array made of 512x512=262144 values. Such values are of float type and range from 0.0 to 1.0. The array has an X,Y coordinate system which originates in the top left corner: thus, position (0,0) is in the top left corner, while position (512,512) is in the bottom right corner.\nThis is how the 2D array looks like (just an excerpt):\nX,Y,Value\n0,0,0.482\n0,1,0.49\n0,2,0.496\n0,3,0.495\n0,4,0.49\n0,5,0.489\n0,6,0.5\n0,7,0.504\n0,8,0.494\n0,9,0.485\nI would like to be able to:\nCount the number of regions of cells which value below a given threshold, i.e. 0.75;\nNote: If two elements touch horizontally, vertically or diagnoally, they belong to one region.\nA:\n<code>\nimport numpy as np\nfrom scipy import ndimage\nnp.random.seed(10)\ngen = np.random.RandomState(0)\nimg = gen.poisson(2, size=(512, 512))\nimg = ndimage.gaussian_filter(img.astype(np.double), (30, 30))\nimg -= img.min()\nimg /= img.max()\nthreshold = 0.75\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def solution(img, threshold):\n    # Insert code here\n    [insert]\n    return result\n</code>"
    },
    {
        "library_id": 28,
        "source_id": 26,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI am working with a 2D numpy array made of 512x512=262144 values. Such values are of float type and range from 0.0 to 1.0. The array has an X,Y coordinate system which originates in the top left corner: thus, position (0,0) is in the top left corner, while position (512,512) is in the bottom right corner.\nThis is how the 2D array looks like (just an excerpt):\nX,Y,Value\n0,0,0.482\n0,1,0.49\n0,2,0.496\n0,3,0.495\n0,4,0.49\n0,5,0.489\n0,6,0.5\n0,7,0.504\n0,8,0.494\n0,9,0.485\nI would like to be able to:\nCount the number of regions of cells which value exceeds a given threshold, i.e. 0.75;\nNote: If two elements touch horizontally, vertically or diagnoally, they belong to one region.\nA:\n<code>\nimport numpy as np\nfrom scipy import ndimage\nnp.random.seed(10)\ngen = np.random.RandomState(0)\nimg = gen.poisson(2, size=(512, 512))\nimg = ndimage.gaussian_filter(img.astype(np.double), (30, 30))\nimg -= img.min()\nexample_img /= img.max()\ndef f(img = example_img):\n    threshold = 0.75\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\n    return result\n</code>\n\n\ndef",
        "answer": "def f(img = example_img):\n    threshold = 0.75\n    return result\nEND SOLUTION"
    },
    {
        "library_id": 29,
        "source_id": 26,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI am working with a 2D numpy array made of 512x512=262144 values. Such values are of float type and range from 0.0 to 1.0. The array has an X,Y coordinate system which originates in the top left corner: thus, position (0,0) is in the top left corner, while position (512,512) is in the bottom right corner.\nThis is how the 2D array looks like (just an excerpt):\nX,Y,Value\n0,0,0.482\n0,1,0.49\n0,2,0.496\n0,3,0.495\n0,4,0.49\n0,5,0.489\n0,6,0.5\n0,7,0.504\n0,8,0.494\n0,9,0.485\nI would like to be able to:\nFind the regions of cells which value exceeds a given threshold, say 0.75;\nNote: If two elements touch horizontally, vertically or diagnoally, they belong to one region.\nDetermine the distance between the center of mass of such regions and the top left corner, which has coordinates (0,0).\nPlease output the distances as a list.\nA:\n<code>\nimport numpy as np\nfrom scipy import ndimage\nnp.random.seed(10)\ngen = np.random.RandomState(0)\nimg = gen.poisson(2, size=(512, 512))\nimg = ndimage.gaussian_filter(img.astype(np.double), (30, 30))\nimg -= img.min()\nimg /= img.max()\nthreshold = 0.75\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(result)\n</code>\n\n\ndef",
        "answer": "def solution(A):\n    result = []\n    # [insert]\n    return result\nEND SOLUTION\n\"\"\""
    },
    {
        "library_id": 30,
        "source_id": 30,
        "prompt": "Complete the Python function given the prompt below:Problem:\nIs there a simple and efficient way to make a sparse scipy matrix (e.g. lil_matrix, or csr_matrix) symmetric? \nCurrently I have a lil sparse matrix, and not both of sA[i,j] and sA[j,i] have element for any i,j.\nWhen populating a large sparse co-occurrence matrix it would be highly inefficient to fill in [row, col] and [col, row] at the same time. What I'd like to be doing is:\nfor i in data:\n    for j in data:\n        if have_element(i, j):\n            lil_sparse_matrix[i, j] = some_value\n            # want to avoid this:\n            # lil_sparse_matrix[j, i] = some_value\n# this is what I'm looking for:\nlil_sparse.make_symmetric() \nand it let sA[i,j] = sA[j,i] for any i, j.\nThis is similar to <a href=\"https://stackoverflow.com/questions/2572916/numpy-smart-symmetric-matrix\">stackoverflow's numpy-smart-symmetric-matrix question, but is particularly for scipy sparse matrices.\nA:\n<code>\nimport numpy as np\nfrom scipy.sparse import lil_matrix\nfrom scipy import sparse\nM= sparse.random(10, 10, density=0.1, format='lil')\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(M)\n</code>\n\n\ndef",
        "answer": "def make_symmetric(A):\n    \"\"\"\n    Given a scipy sparse matrix, make it symmetric.\n    \"\"\"\n    A = A + A.T\n    return A\nEND SOLUTION\n\"\"\""
    },
    {
        "library_id": 31,
        "source_id": 30,
        "prompt": "Complete the Python function given the prompt below:Problem:\nIs there a simple and efficient way to make a sparse scipy matrix (e.g. lil_matrix, or csr_matrix) symmetric? \nCurrently I have a lil sparse matrix, and not both of sA[i,j] and sA[j,i] have element for any i,j.\nWhen populating a large sparse co-occurrence matrix it would be highly inefficient to fill in [row, col] and [col, row] at the same time. What I'd like to be doing is:\nfor i in data:\n    for j in data:\n        if have_element(i, j):\n            lil_sparse_matrix[i, j] = some_value\n            # want to avoid this:\n            # lil_sparse_matrix[j, i] = some_value\n# this is what I'm looking for:\nlil_sparse.make_symmetric() \nand it let sA[i,j] = sA[j,i] for any i, j.\nThis is similar to <a href=\"https://stackoverflow.com/questions/2572916/numpy-smart-symmetric-matrix\">stackoverflow's numpy-smart-symmetric-matrix question, but is particularly for scipy sparse matrices.\nA:\n<code>\nimport numpy as np\nfrom scipy.sparse import lil_matrix\nexample_sA = sparse.random(10, 10, density=0.1, format='lil')\ndef f(sA = example_sA):\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\n    return sA\n</code>\n\n\ndef",
        "answer": "def f(sA = example_sA):\n    return sA"
    },
    {
        "library_id": 32,
        "source_id": 32,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI'm trying to reduce noise in a binary python array by removing all completely isolated single cells, i.e. setting \"1\" value cells to 0 if they are completely surrounded by other \"0\"s like this:\n0 0 0\n0 1 0\n0 0 0\n I have been able to get a working solution by removing blobs with sizes equal to 1 using a loop, but this seems like a very inefficient solution for large arrays.\nIn this case, eroding and dilating my array won't work as it will also remove features with a width of 1. I feel the solution lies somewhere within the scipy.ndimage package, but so far I haven't been able to crack it. Any help would be greatly appreciated!\nA:\n<code>\nimport numpy as np\nimport scipy.ndimage\nsquare = np.zeros((32, 32))\nsquare[10:-10, 10:-10] = 1\nnp.random.seed(12)\nx, y = (32*np.random.random((2, 20))).astype(int)\nsquare[x, y] = 1\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(square)\n</code>\n\n\ndef",
        "answer": "def remove_isolated_pixels(A):\n    B = scipy.ndimage.binary_erosion(A)\n    C = scipy.ndimage.binary_dilation(B)\n    return A ^ C\nEND SOLUTION\n\"\"\""
    },
    {
        "library_id": 33,
        "source_id": 32,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI'm trying to reduce noise in a python image array by removing all completely isolated single cells, i.e. setting nonzero value cells to 0 if they are completely surrounded by other \"0\"s like this:\n0 0 0\n0 8 0\n0 0 0\n I have been able to get a working solution by removing blobs with sizes equal to 1 using a loop, but this seems like a very inefficient solution for large arrays.\nIn this case, eroding and dilating my array won't work as it will also remove features with a width of 1. I feel the solution lies somewhere within the scipy.ndimage package, but so far I haven't been able to crack it. Any help would be greatly appreciated!\nA:\n<code>\nimport numpy as np\nimport scipy.ndimage\nsquare = np.zeros((32, 32))\nsquare[10:-10, 10:-10] = np.random.randint(1, 255, size = (12, 12))\nnp.random.seed(12)\nx, y = (32*np.random.random((2, 20))).astype(int)\nsquare[x, y] = np.random.randint(1, 255, size = (20,))\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(square)\n</code>\n\n\ndef",
        "answer": "def reduce_noise(A):\n    B = A.copy()\n    for i in range(A.shape[0]):\n        for j in range(A.shape[1]):\n            if A[i,j] == 0:\n                if np.sum(A[i-1:i+2, j-1:j+2]) == 0:\n                    B[i,j] = 0\n    return B"
    },
    {
        "library_id": 34,
        "source_id": 34,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have a sparse 988x1 vector (stored in col, a column in a csr_matrix) created through scipy.sparse. Is there a way to gets its mean and standard deviation without having to convert the sparse matrix to a dense one?\nnumpy.mean seems to only work for dense vectors.\nA:\n<code>\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nnp.random.seed(10)\narr = np.random.randint(4,size=(988,988))\nsA = csr_matrix(arr)\ncol = sA.getcol(0)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(mean)\nprint(standard_deviation)\n</code>\n\n\ndef",
        "answer": "def mean(arr):\n    return np.mean(arr)"
    },
    {
        "library_id": 35,
        "source_id": 34,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have a sparse 988x1 vector (stored in col, a column in a csr_matrix) created through scipy.sparse. Is there a way to gets its max and min value without having to convert the sparse matrix to a dense one?\nnumpy.max seems to only work for dense vectors.\nA:\n<code>\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nnp.random.seed(10)\narr = np.random.randint(4,size=(988,988))\nsA = csr_matrix(arr)\ncol = sA.getcol(0)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(Max)\nprint(Min)\n</code>\n\n\ndef",
        "answer": "def max_min(arr):\n    \"\"\"\n    Given a sparse vector, find the max and min values\n    \"\"\"\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n    # Your code here\n"
    },
    {
        "library_id": 36,
        "source_id": 34,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI have a sparse 988x1 vector (stored in col, a column in a csr_matrix) created through scipy.sparse. Is there a way to gets its median and mode value without having to convert the sparse matrix to a dense one?\nnumpy.median seems to only work for dense vectors.\nA:\n<code>\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nnp.random.seed(10)\narr = np.random.randint(4,size=(988,988))\nsA = csr_matrix(arr)\ncol = sA.getcol(0)\n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(Median)\nprint(Mode)\n</code>\n\n\ndef",
        "answer": "def median(arr):\n    return np.median(arr)"
    },
    {
        "library_id": 37,
        "source_id": 37,
        "prompt": "Complete the Python function given the prompt below:Problem:\nI'd like to achieve a fourier series development for a x-y-dataset using numpy and scipy.\nAt first I want to fit my data with the first 8 cosines and plot additionally only the first harmonic. So I wrote the following two function defintions:\n# fourier series defintions\ntau = 0.045\ndef fourier8(x, a1, a2, a3, a4, a5, a6, a7, a8):\n    return a1 * np.cos(1 * np.pi / tau * x) + \\\n           a2 * np.cos(2 * np.pi / tau * x) + \\\n           a3 * np.cos(3 * np.pi / tau * x) + \\\n           a4 * np.cos(4 * np.pi / tau * x) + \\\n           a5 * np.cos(5 * np.pi / tau * x) + \\\n           a6 * np.cos(6 * np.pi / tau * x) + \\\n           a7 * np.cos(7 * np.pi / tau * x) + \\\n           a8 * np.cos(8 * np.pi / tau * x)\ndef fourier1(x, a1):\n    return a1 * np.cos(1 * np.pi / tau * x)\nThen I use them to fit my data:\n# import and filename\nfilename = 'data.txt'\nimport numpy as np\nfrom scipy.optimize import curve_fit\nz, Ua = np.loadtxt(filename,delimiter=',', unpack=True)\ntau = 0.045\npopt, pcov = curve_fit(fourier8, z, Ua)\nwhich works as desired\nBut know I got stuck making it generic for arbitary orders of harmonics, e.g. I want to fit my data with the first fifteen harmonics.\nHow could I achieve that without defining fourier1, fourier2, fourier3..., fourier15?\nBy the way, initial guess of a1,a2,\u2026 should be set to default value.\nA:\n<code>\nfrom scipy.optimize import curve_fit\nimport numpy as np\ns = '''1.000000000000000021e-03,2.794682735905079767e+02\n4.000000000000000083e-03,2.757183469104809888e+02\n1.400000000000000029e-02,2.791403179603880176e+02\n2.099999999999999784e-02,1.781413355804160119e+02\n3.300000000000000155e-02,-2.798375517344049968e+02\n4.199999999999999567e-02,-2.770513900380149721e+02\n5.100000000000000366e-02,-2.713769422793179729e+02\n6.900000000000000577e-02,1.280740698304900036e+02\n7.799999999999999989e-02,2.800801708984579932e+02\n8.999999999999999667e-02,2.790400329037249776e+02'''.replace('\\n', ';')\narr = np.matrix(s)\nz = np.array(arr[:, 0]).squeeze()\nUa = np.array(arr[:, 1]).squeeze()\ntau = 0.045\ndegree = 15    \n</code>\nBEGIN SOLUTION\n<code>\n[insert]\n</code>\nEND SOLUTION\n<code>\nprint(popt, pcov)\n</code>\n\n\ndef",
        "answer": "def fourier15(x, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15):\n    return a1 * np.cos(1 * np.pi / tau * x) + \\\n           a2 * np.cos(2 * np.pi / tau * x) + \\\n           a3 * np.cos(3 * np.pi / tau * x) + \\\n           a4 * np.cos(4 * np.pi / tau * x) + \\\n           a5 * np.cos(5 * np.pi / tau * x) + \\\n           a6 * np.cos(6 * np.pi / tau * x) + \\\n           a7 * np.cos(7 * np.pi / tau * x) + \\\n           a8 * np.cos(8 * np.pi / tau * x) + \\\n           a9 * np.cos(9 * np.pi / tau * x) + \\\n           a10 * np.cos(10 * np.pi / tau * x) + \\\n           a11 * np.cos(11 * np.pi / tau * x) + \\\n           a12 * np.cos(12 * np.pi / tau * x) + \\\n           a13 * np.cos(13 * np.pi / tau * x) + \\\n           a14 * np.cos(14 * np.pi / tau * x) + \\\n           a15 * np.cos(15 * np.pi / tau * x)\ndef fourier15(x, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15):\n    return a1 * np.cos(1 * np.pi / tau * x) + \\\n           a2 * np.cos(2 * np.pi / tau * x) + \\\n           a3 * np.cos(3 * np.pi / tau * x) + \\"
    }
]